# Project 1 - Sentence Constructor

## French Sentence Constructor ðŸ‡«ðŸ‡·

This is the first project of the GenAI Cloud Project Bootcamp to help students learn French in a more interactive way. 

## Goal of the Project

The goal of the project is to see how well the different AI assistant models respond to the prompts , and are they following the instructions , their speed, feedback style, accuracy and vocabulary.

## What's This All About?

Ever tried learning a new language and wished you had a friendly guide available 24/7? That's exactly what this project aims to be! Instead of just giving you translations, this AI teaching assistant helps you figure out how to construct French sentences on your own.

Think of it as having a patient tutor who gives you hints and guides you through the process, rather than just giving you the answers.

## Why this project ?

This project was inspired by a real-world scenario: a language school wanting to help their students practice between classes. The goal is to make learning French more engaging and accessible, while ensuring students actually learn rather than just getting quick translations.

## How It Works

The AI assistant:

- Guides you through translating English sentences to French
- Gives helpful hints when you're stuck
- Explains grammar concepts as needed
- Keeps the focus on learning, not just translating

## Findings and Summary

Exploring questions like:

How well can AI handle being a teaching assistant?
Should we use one AI for everything or split tasks between specialized assistants?
What's the best way to move from prototype to a real product?


# AI Language Teaching Assistant Comparison Analysis

## Comparative Analysis Table

| Criteria | ChatGPT | Claude | Gemini | LLaMA-3 | Mistral | Grok | Deepseek |
|----------|---------|--------|---------|----------|----------|------|-----------|
| Prompt Adherence | Partial | High | High | High | Poor | High | Poor |
| Instruction Following | Mixed - Initially provided too much vocabulary, corrected after feedback | Strong - Followed all formatting and teaching guidelines | Strong - Clear teaching structure and progressive feedback | Strong - Provided detailed formatting and examples | Poor - Ignored prompt format completely | Good - Followed teaching guidelines closely | Poor - Completely ignored prompt structure |
| Teaching Approach | Interactive, encourages practice | Structured, professional, comprehensive | Interactive, progressive feedback | Methodical, example-based | Generic response, not tailored | Step-by-step guidance | Oversimplified, basic |
| Vocabulary Table Format | Initially exceeded 3-word limit, later corrected | Correct 3-word limit | Appropriate length and format | Correct format and length | Standard table but ignored constraints | Adhered to format requirements | Minimal, basic format |
| Feedback Style | Encouraging, uses emojis | Professional, analytical | Constructive, detailed | Direct, clear | Generic | Concise, focused | Too basic |
| Response Structure | Clear but initially verbose | Well-organized, systematic | Logical progression | Well-documented | Disorganized | Clear, systematic | Oversimplified |
| Additional Features | Includes visual aids (images) | Includes next practice exercises | Progressive difficulty | Comprehensive examples | None | Includes practice sentences | None |
| Speed/Efficiency | Multiple iterations needed | Direct and efficient | Progressive approach | Detailed but efficient | Inefficient | Efficient | Too basic |
| Error Analysis | Surface level | Detailed grammatical analysis | Progressive error correction | Clear error identification | Generic | Specific error focus | None provided |
| Overall Effectiveness | Good but needed refinement | Excellent | Very Good | Very Good | Poor | Good | Poor |

## Key Findings

1. **Best Overall Performance**: Claude and Gemini showed the most balanced and effective approach, combining thorough instruction with appropriate formatting and feedback.

2. **Adherence to Instructions**:
   - Strong: Claude, Gemini, LLaMA-3, Grok
   - Mixed: ChatGPT
   - Poor: Mistral, Deepseek

3. **Teaching Methodology**:
   - Most Professional: Claude
   - Most Interactive: Gemini
   - Most Structured: LLaMA-3
   - Most Basic: Deepseek

4. **Areas for Improvement**:
   - ChatGPT: Initial vocabulary control
   - Mistral: Complete restructuring needed
   - Deepseek: Needs major improvements in all areas

5. **Unique Strengths**:
   - ChatGPT: Visual aids
   - Claude: Comprehensive analysis
   - Gemini: Progressive feedback
   - LLaMA-3: Detailed documentation
   - Grok: Focused approach
    

## Recommendations

1. **For Students**: Claude or Gemini would be the most effective choices for language learning due to their balanced approach and clear feedback.

2. **For Teachers**: LLaMA-3 provides the most comprehensive documentation and example structure.

3. **For Quick Practice**: Grok offers an efficient, focused approach while maintaining quality.

4. **Avoid**: Mistral and Deepseek in their current form, as they don't follow the required teaching format and provide insufficient guidance.









Made with â˜• during the Free GenAI Cloud Project Bootcamp (2025)